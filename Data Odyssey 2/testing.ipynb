{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import torch  \n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer  \n",
    "import pickle\n",
    "\n",
    "# Define the path where you saved the model  \n",
    "MODEL_SAVE_DIR = './model_artifacts/fine_tuned_model'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./analysis_results.pkl', 'rb') as file:\n",
    "    loaded_analysis_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tokenizer  \n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_SAVE_DIR)  \n",
    "\n",
    "# Set the pad token if not already set  \n",
    "if tokenizer.pad_token is None:  \n",
    "    tokenizer.pad_token = tokenizer.eos_token  \n",
    "\n",
    "# Set into CPU\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Load the model  \n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_SAVE_DIR).to(device)  \n",
    "\n",
    "# Set the model to evaluation mode  \n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt=\"The\", max_length=50):  \n",
    "    # Encode the input prompt  \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)  \n",
    "\n",
    "    # Generate text  \n",
    "    with torch.no_grad():  \n",
    "        output = model.generate(  \n",
    "            input_ids,   \n",
    "            max_length=max_length,   \n",
    "            num_return_sequences=1,  \n",
    "            no_repeat_ngram_size=2,  \n",
    "            do_sample=True,  \n",
    "            top_k=50,  \n",
    "            top_p=0.95,  \n",
    "            pad_token_id=tokenizer.eos_token_id  \n",
    "        )  \n",
    "\n",
    "    # Decode and return the generated text  \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligenceione code language communication protocol interface system software code application program interface interface programming system code interface design code tool interface application interface programation interface software interface code system interface information system architecture system system design problem address system memory interface computer program system implementation program code code software software program program subsystem program software system programming interface compiler code implementation softwareat computer system program understanding system programmer systema system user code program computer interface platform system understanding computer code design system research system systems program development system\n"
     ]
    }
   ],
   "source": [
    "# Example usage  \n",
    "print(generate_text(prompt=\"Artificial intelligence\", max_length=100))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPUML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
